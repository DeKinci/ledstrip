#!/usr/bin/env python3
"""
Compress web resources (HTML) with Brotli and generate C++ headers.
Only regenerates if source files have changed (SHA256 hash check).
Reads resource configuration from rsc/resources.txt
"""

import os
import sys
import hashlib

# Auto-install brotli if missing (for PlatformIO)
try:
    import brotli
except ImportError:
    print("brotli module not found, installing...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "brotli"])
    import brotli

# Configuration
BROTLI_QUALITY = 11  # Maximum compression (slower build, smallest size)
RESOURCES_FILE = "rsc/resources.txt"
OUTPUT_DIR = "src/rsc"

def calculate_hash(file_path):
    """Calculate SHA256 hash of file"""
    sha256 = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256.update(chunk)
    return sha256.hexdigest()

def read_stored_hash(header_file):
    """Read hash from existing header file"""
    if not os.path.exists(header_file):
        return None

    try:
        with open(header_file, 'r', encoding='utf-8') as f:
            first_line = f.readline()
            if '// Hash:' in first_line:
                return first_line.split('Hash:')[1].strip()
    except:
        pass

    return None

def should_regenerate(source_file, header_file):
    """Check if regeneration is needed"""
    if not os.path.exists(header_file):
        print(f"  → Header doesn't exist, will generate")
        return True

    old_hash = read_stored_hash(header_file)
    if old_hash is None:
        print(f"  → No hash found in header, will regenerate")
        return True

    new_hash = calculate_hash(source_file)

    if old_hash != new_hash:
        print(f"  → Source changed (hash mismatch), will regenerate")
        return True

    print(f"  → Source unchanged, skipping")
    return False

def sanitize_name(filename):
    """Convert filename to valid C identifier, keeping extension"""
    name = os.path.basename(filename)
    # Replace dots and dashes with underscores, but keep the structure
    return name.replace('.', '_').replace('-', '_')

def process_brotli(source_path, output_path, var_name):
    """Compress with Brotli and generate header"""
    # Read source
    with open(source_path, 'rb') as f:
        data = f.read()

    original_size = len(data)
    print(f"  → Original size: {original_size:,} bytes")

    # Compress with Brotli
    compressed = brotli.compress(data, quality=BROTLI_QUALITY)
    compressed_size = len(compressed)
    ratio = (1 - compressed_size / original_size) * 100

    print(f"  → Compressed size: {compressed_size:,} bytes ({ratio:.1f}% reduction)")

    # Calculate hash
    source_hash = calculate_hash(source_path)

    # Generate header guard
    guard = f"RSC_{var_name.upper()}_H"

    # Generate C++ header
    header_content = f"""// Hash: {source_hash}
// Generated from: {source_path}
// Compressed with Brotli (quality {BROTLI_QUALITY})
// Original size: {original_size:,} bytes
// Compressed size: {compressed_size:,} bytes ({ratio:.1f}% reduction)
// DO NOT EDIT - Auto-generated by scripts/compress_web_resources.py

#ifndef {guard}
#define {guard}

#include <Arduino.h>

const uint8_t {var_name}[] PROGMEM = {{
"""

    # Write compressed data as hex array
    bytes_per_line = 16
    for i in range(0, len(compressed), bytes_per_line):
        chunk = compressed[i:i+bytes_per_line]
        hex_bytes = ', '.join(f'0x{b:02x}' for b in chunk)
        header_content += f"    {hex_bytes},\n"

    # Remove trailing comma and newline
    header_content = header_content.rstrip(',\n') + '\n'

    header_content += f"""
}};

const size_t {var_name}_len = {compressed_size};

#endif // {guard}
"""

    # Write header file
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(header_content)

    print(f"  ✓ Generated: {output_path}")
    return True

def process_original(source_path, output_path, var_name):
    """Include original file without compression"""
    # Read source
    with open(source_path, 'rb') as f:
        data = f.read()

    size = len(data)
    print(f"  → Original size: {size:,} bytes (no compression)")

    # Calculate hash
    source_hash = calculate_hash(source_path)

    # Generate header guard
    guard = f"RSC_{var_name.upper()}_H"

    # Generate C++ header
    header_content = f"""// Hash: {source_hash}
// Generated from: {source_path}
// Original (no compression)
// Size: {size:,} bytes
// DO NOT EDIT - Auto-generated by scripts/compress_web_resources.py

#ifndef {guard}
#define {guard}

#include <Arduino.h>

const uint8_t {var_name}[] PROGMEM = {{
"""

    # Write data as hex array
    bytes_per_line = 16
    for i in range(0, len(data), bytes_per_line):
        chunk = data[i:i+bytes_per_line]
        hex_bytes = ', '.join(f'0x{b:02x}' for b in chunk)
        header_content += f"    {hex_bytes},\n"

    # Remove trailing comma and newline
    header_content = header_content.rstrip(',\n') + '\n'

    header_content += f"""
}};

const size_t {var_name}_len = {size};

#endif // {guard}
"""

    # Write header file
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(header_content)

    print(f"  ✓ Generated: {output_path}")
    return True

def parse_resources_file(resources_file):
    """Parse resources.txt and return list of resources"""
    resources = []

    if not os.path.exists(resources_file):
        print(f"⚠️  WARNING: Resources file not found: {resources_file}")
        return resources

    with open(resources_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()

            # Skip empty lines and comments
            if not line or line.startswith('#'):
                continue

            # Parse: filename processing_type
            parts = line.split()
            if len(parts) != 2:
                print(f"⚠️  WARNING: Invalid line {line_num}: {line}")
                continue

            filename, processing = parts

            # Validate processing type
            if processing not in ['brotli', 'original']:
                print(f"⚠️  WARNING: Unknown processing type '{processing}' on line {line_num}")
                continue

            # Build resource configuration
            source_path = os.path.join('rsc', filename)
            var_name = sanitize_name(filename)

            if processing == 'brotli':
                var_name += '_br'

            output_filename = f"w_{var_name}.h"
            output_path = os.path.join(OUTPUT_DIR, output_filename)

            resources.append({
                'source': source_path,
                'output': output_path,
                'var_name': var_name,
                'processing': processing
            })

    return resources

def process_resource(resource):
    """Process a single resource"""
    source = resource['source']
    output = resource['output']
    var_name = resource['var_name']
    processing = resource['processing']

    print(f"\nProcessing: {source} ({processing})")

    # Check if source exists
    if not os.path.exists(source):
        print(f"  ⚠️  Source file not found, skipping")
        return False

    # Check if regeneration needed
    if not should_regenerate(source, output):
        return False

    # Process based on type
    if processing == 'brotli':
        return process_brotli(source, output, var_name)
    elif processing == 'original':
        return process_original(source, output, var_name)
    else:
        print(f"  ⚠️  Unknown processing type: {processing}")
        return False

def main():
    print("=" * 60)
    print("Web Resource Processing")
    print("=" * 60)

    # Get project root
    # When run by PlatformIO, __file__ is not defined, use cwd
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
    except NameError:
        # Running under PlatformIO/SCons - already in project root
        project_root = os.getcwd()

    os.chdir(project_root)

    print(f"Project root: {project_root}")
    print(f"Reading resources from: {RESOURCES_FILE}")

    # Parse resources file
    resources = parse_resources_file(RESOURCES_FILE)

    if not resources:
        print("\n⚠️  No resources found to process")
        return 0

    print(f"Found {len(resources)} resource(s) to process")

    # Process each resource
    regenerated_count = 0
    for resource in resources:
        if process_resource(resource):
            regenerated_count += 1

    print("\n" + "=" * 60)
    if regenerated_count > 0:
        print(f"✓ Regenerated {regenerated_count} file(s)")
    else:
        print("✓ All files up to date, no regeneration needed")
    print("=" * 60)

    return 0

main()
